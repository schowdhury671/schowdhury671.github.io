 <!DOCTYPE html>
<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="UTF-8">
    <title>Simple Research Garden</title>
    <link rel="stylesheet" href="main.css">
    <link rel="stylesheet" href="garden.css">
    <style id="flower_css"></style>
</head>
<body>
    <!-- Research Garden -->
    <svg id="flower_template" xmlns="http://www.w3.org/2000/svg" viewBox="-10 -10 20 20">
        <ellipse rx="10" ry="20" transform="rotate(0)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(45)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(90)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(135)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(180)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(225)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(270)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <ellipse rx="10" ry="20" transform="rotate(315)" fill="[[COLOR]]" class="petal [[FLOWER_CLASS]]"/>
        <circle r="6" fill="white"/>
    </svg>
    <div id="garden_title">Philippe's Research Garden</div>
    <div id="garden_container">
        <svg id="garden" preserveAspectRatio="xMinYMin meet"></svg>
     </div>
     <div id="coauthor_hall_of_fame">
        <div id="coauthor_title">Recurrent Coauthors ("Hall of Friends")</div>
        <div id="coauthor_list"></div>
    </div>
    <div id="paper_modal">
        <!-- a close icon at the top right -->
        <div id="paper_modal_close" onclick="$('#paper_modal').fadeOut(200);">X</div>
        <div id="paper_modal_title"></div>
        <div id="paper_modal_venue"></div>
        <div id="paper_modal_content"></div>
        <div id="paper_modal_links"></div>
    </div>

    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

    <script src="garden.js?v=2"></script>
    <script>
        var papers = [
        {"id": "newslens", "title": "NewsLens", "venue": "ACL2017 Workshop", "url": "https://aclanthology.org/W17-2701.pdf", "root_node": 1, "root_name": "Reading Interfaces\n2016-2023", "root_color": "#FA9189", "coauthors": ["Marti A. Hearst"], "full_title": "newsLens: building and visualizing long-ranging news stories", "summary": "My first foray into news reading interfaces, presented at the News Workshop of ACL 2017. The work presents how a large-scale stream of news articles can be organized into evolving news timelines, how to name and visualize them."},
        {"id": "news_chatbot", "title": "News Chatbot", "venue": "ACL2020", "url": "https://arxiv.org/abs/2105.05392", "parent": "newslens", "coauthors": ["John Canny", "Marti A. Hearst"], "full_title": "What's The Latest? A Question-driven News Chatbot", "summary": "For the NewsLens stories, what would it look like to 'chat' with a system about an evolving news story's that can have 1000+ articles (pre-ChatGPT !!). Neat Finding: if you recommend questions to users, they can have fairly long conversation, reading through more than an average article's length of content.", "additional_links": {"video": "https://slideslive.com/38928615/whats-the-latest-a-questiondriven-news-chatbot"}},
        {"id": "newspod", "title": "Podcasts", "venue": "IUI2022", "url": "https://arxiv.org/abs/2202.07146", "parent": "news_chatbot", "coauthors": ["Elicia Ye", "Srujay Korlakunta", "John Canny", "Marti A. Hearst"], "full_title": "NewsPod: Automatic and Interactive News Podcasts", "summary": "Taking Newslens and its chat to the next level: by exploring whether stoires can be turned into conversational (multi-voice) and interactive (user can speak) podcasts. Neat Finding: using multiple voices when synthesizing speech lowers user fatigue, and adding a Q&A format reduces monotonicity. Users are sometimes willing to jump in and ask their own questions.", "additional_links": {"live_demo": "https://newspod.github.io/", "Interview (Apple Podcast)": "https://podcasts.apple.com/ca/podcast/like-your-new-best-friend-an-ai-chatbot/id1639175294?i=1000575694297"}},
        {"id": "news_headline_grouping", "title": "Headline Grouping", "venue": "NAACL2021", "url": "https://arxiv.org/abs/2105.05391", "parent": "news_chatbot", "coauthors": ["Marti A. Hearst"], "full_title": "News Headline Grouping as a Challenging NLU Task", "summary": "Focused work on a challenging NLP task related to news headline writing. Can we automatically detect when two headlines relate to the same real-world event? It happens to be challenging because of the complex process involved in crafting news headlines.", "additional_links": {"code": "https://github.com/tingofurro/headline_grouping", "data (HF)": "https://huggingface.co/philippelaban/headline_grouping", "video": "https://aclanthology.org/2021.naacl-main.255.mp4"}},
        {"id": "discord_questions", "title": "Discord Questions", "venue": "EMNLP2022", "url": "https://arxiv.org/abs/2211.05007", "parent": "news_headline_grouping", "coauthors": ["Chien-Sheng Wu", "Lidiya Murakhovs'ka", "Xiang 'Anthony' Chen", "Caiming Xiong"], "full_title": "Discord Questions: A Computational Approach To Diversity Analysis in News Coverage", "summary": "Given a set of news articles (and/or documents) that cover a common topic (news event), can we find key questions that surface when the sources agree, or disagree. Can these be used to surface the diversity in coverage that exists in the corpus? Neat Finding: even pre-ChatGPT, this was possible: over-generate 100+ questions, and filter out to the few that fit strict criteria.", "additional_links": {"video": "https://aclanthology.org/2022.findings-emnlp.380.mp4", "code": "https://github.com/salesforce/discord_questions", "data": "https://huggingface.co/Salesforce/qa_consolidation", "models": "https://huggingface.co/Salesforce/discord_qg"}},
        {"id": "assembly", "title": "Assembly", "venue": "CHI2023", "url": "https://arxiv.org/abs/2302.08997", "parent": "discord_questions", "coauthors": ["Chien-Sheng Wu", "Lidiya Murakhovs'ka", "Xiang 'Anthony' Chen", "Caiming Xiong"], "full_title": "Designing and Evaluating Interfaces that Highlight News Coverage Diversity Using Discord Questions", "summary": "Once we have Discord Questions, how do we use them in practice in news reading interfaces, both for journalism professionals, and everyday newsreaders (the 'Assembly' interfaces). Neat Finding: we showed in a study with 100+ participants that the annotated article interface leads to better access to coverage diversity, while not being more complicated to use (success!).", "additional_links": {"video": "https://www.youtube.com/watch?v=s2mBv3xD7Lg"}},
        {"id": "diverse_summ", "title": "DiverseSumm", "venue": "NAACL2024", "url": "https://arxiv.org/abs/2309.09369", "parent": "assembly", "coauthors": ["Kung-Hsiang Huang", "Alexander R. Fabbri", "Prafulla Kumar Choubey", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Embrace Divergence for Richer Insights: A Multi-document Summarization Benchmark and a Case Study on Summarizing Diverse Information from News Articles", "summary": "Follow-up of Discord Questions & Assembly. Once we've found a topic of discord within a corpus of documents, how good are LLMs at describing this diversity when they summarize the information. Neat finding: LLMs are not so good at nuanced summarization, and tend to focus on information either at the top/bottom of their context window (arbitrary), or on predominantly represent opinion. Work led by Steeve Huang when he was an intern at Salesforce Research!", "additional_links": {"code/data": "https://github.com/salesforce/DiverseSumm"}},
        {"id": "summaryloop", "title": "Summary Loop", "venue": "ACL2020", "url": "https://arxiv.org/abs/2105.05361", "root_node": 1, "root_name": "Summarization\n2019-now", "root_color": "#FFE699", "coauthors": ["Andrew Hsi", "John Canny", "Marti A. Hearst"], "full_title": "The Summary Loop: Learning to Write Abstractive Summaries Without Examples", "summary": "My first foray into summarization! We designed an entirely unsupervised method for summarization that relied on RL optimization (before it was cool) to train a 'language model' (GPT2) to jointly optimize information coverage & fluency. Neat Idea: the most complex element to define was the Coverage scoring method, check it out in the paper.", "additional_links": {"video": "https://slideslive.com/38929183/summary-loop-unsupervised-abstractive-summarization", "code": "https://github.com/CannyLab/summary_loop", "models": "https://huggingface.co/philippelaban/summary_loop46"}},
        {"id": "summac", "title": "SummaC", "venue": "TACL2021", "url": "https://arxiv.org/abs/2111.09525", "parent": "summaryloop", "coauthors": ["Tobias Schnabel", "Paul N. Bennett", "Marti A. Hearst"], "full_title": "SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization", "summary": "First adventures with factuality/faithfulness/consistency in text generation & summarization. At the time, most of the work had shown NLI methods did not work reliably to detect factual errors in generated text, and relied instead on more complex QG/QA pipelines. The work shows that more modern NLI models, when used at the right granularity, are competitive and much faster to run. We released the two models & the benchmark we created (SummaC).", "additional_links": {"video": "https://aclanthology.org/2022.tacl-1.10.mp4", "code/data": "https://github.com/tingofurro/summac"}},
        {"id": "aggrefact", "title": "AggreFact", "venue": "ACL2023", "url": "https://arxiv.org/abs/2205.12854", "parent": "summac", "coauthors": ["Liyan Tang", "Tanya Goyal", "Alexander R. Fabbri", "Jiacheng Xu", "Semih Yavuz", "Wojciech Kryściński", "Justin F. Rousseau", "Greg Durrett"], "full_title": "Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors", "summary": "Work led by Liyan Tang on creating a larger-scale benchmark for factuality in summarization (AggreFact) to better understand error types that occur across model generations. Neat Finding: the distribution of factual error types shifts with different generations of models. As generative models get better, the kinds of factual errors they make become more subtle... and more difficult to catch. (oh no!)", "additional_links": {"video": "https://aclanthology.org/2023.acl-long.650.mp4", "data": "https://github.com/Liyan06/AggreFact"}},
        {"id": "summedits", "title": "SummEdits", "venue": "EMNLP2023", "url": "https://arxiv.org/abs/2305.14540", "parent": "summac", "indirect_connections": ["minicheck"], "coauthors": ["Wojciech Kryściński", "Divyansh Agarwal", "Alexander R. Fabbri", "Caiming Xiong", "Shafiq Joty", "Chien-Sheng Wu"], "full_title": "LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond", "summary": "First work leveraging LLMs (GPT-3.5-turbo)! Can we use an LLM as part of a benchmark creation process to lower the cost of data acquisition while maintaining quality. Neat Finding: we create a dataset for summary factual inconsistency detection that costs 20x less per sample with very high IAA. Most LLMs at the time struggled to beat near-random performance on SummEdits.", "additional_links": {"video": "https://aclanthology.org/2023.emnlp-main.600.mp4", "data (hf)": "https://huggingface.co/datasets/Salesforce/summedits", "code": "https://github.com/salesforce/factualNLG"}},
        {"id": "minicheck", "title": "MiniCheck", "venue": "EMNLP2024", "url": "https://arxiv.org/abs/2404.10774", "parent": "aggrefact", "is_left_child": 1, "coauthors": ["Liyan Tang", "Greg Durrett"], "full_title": "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents", "summary": "Work led by Liyan Tang. Very clever data synthesis process to create challenging (positive/negative) samples for factual inconsistency detection. When training a model on the synthetic data, we obtain a factual inconsistency checker as good as the top LLMs (Claude / GPT) but 300x cheaper to run!", "additional_links": {"code": "https://github.com/Liyan06/MiniCheck", "leaderboard": "https://llm-aggrefact.github.io/", "model (hf)": "https://huggingface.co/bespokelabs/Bespoke-MiniCheck-7B", "data (hf)": "https://huggingface.co/datasets/lytang/LLM-AggreFact"}},
        {"id": "summary_of_a_haystack", "title": "Summary of a Haystack", "venue": "EMNLP2024", "url": "https://arxiv.org/abs/2407.01370", "parent": "summedits", "indirect_connections": ["diverse_summ"], "coauthors": ["Alexander R. Fabbri", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems", "summary": "How good are LLMs or RAG systems at dealing with long-context (~100k tokens) and precisely summarizing and citing back to relevant documents. Alex Fabbri & I very carefully synthesized Haystacks of documents to explore the subject. Neat Finding: in 2024, RAG vs. long-context LLMs is not a winner takes all (yet). RAGs are better when citation/attribution is important, whereas long-context single-step is more competitive when information (without citation) is desired.", "additional_links": {"data (hf)": "https://huggingface.co/datasets/Salesforce/summary-of-a-haystack", "code": "https://github.com/salesforce/summary-of-a-haystack"}},
        {"id": "answer_engine_eval", "title": "Answer Engine Eval.", "venue": "arXiv", "url": "https://arxiv.org/abs/2410.22349", "parent": "summary_of_a_haystack", "indirect_connections": ["minicheck"], "coauthors": ["Pranav Narayanan Venkit", "Yilun Zhou", "Yixin Mao", "Chien-Sheng Wu"], "full_title": "Search Engines in an AI Era: The False Promise of Factual and Verifiable Source-Cited Responses", "summary": "Work led by Pranav Venkit as an intern at Salesforce Research. Explored whether 'answer engines' (generative search engines, which are simply RAG-based summarization systems) capbale of producing accurate and attributed answers to technical user queries. Neat Finding: the qualitative study led to a quantitative framework with ~8 metrics, most of which current answer engines struggle on.", "additional_links": {"code": "https://github.com/SalesforceAIResearch/answer-engine-eval"}},
        {"id": "keepitsimple", "title": "Keep It Simple", "venue": "ACL2021", "url": "https://arxiv.org/abs/2107.03444", "root_node": 1, "root_name": "Writing/Editing/Simplifying\n2020-now", "root_color": "#B3F5BC", "indirect_connections": ["summaryloop"], "coauthors": ["Tobias Schnabel", "Paul Bennett", "Marti A. Hearst"], "full_title": "Keep it Simple: Unsupervised Simplification of Multi-Paragraph Text", "summary": "First baby steps in the field of simplification (a sister task to summarization). We approached it in an entirely unsupervised way (a la Summary Loop), by crafting rewards for fluency, relevance, and simplicity, and optimizing through RL. Neat Finding: an algorithmic improvement to the popular SCST algorithm (k-SCST) which yielded much more stable training, and better models. Also: a focus on paragraph-level (rather than sentence-level) simplification, which was not so common at the time!", "additional_links": {"code": "https://github.com/tingofurro/keep_it_simple", "video": "https://aclanthology.org/2021.acl-long.498.mp4", "model": "https://huggingface.co/philippelaban/keep_it_simple"}},
        {"id": "swipe", "title": "SWiPE", "venue": "ACL2023", "url": "https://arxiv.org/abs/2305.19204", "parent": "keepitsimple", "coauthors": ["Jesse Vig", "Wojciech Kryscinski", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "SWiPE: A Dataset for Document-Level Simplification of Wikipedia Pages", "summary": "Improved the extraction process of simplification document pairs from Simple Wikipedia, showing that Swiki is a great resource to study the simplification process. Prior work had mostly disregarded SWiki in favor of less publicly available datasets such as Newsela.", "additional_links": {"code": "https://github.com/salesforce/simplification"}},
        {"id": "inksync", "title": "InkSync", "venue": "UIST2024", "url": "https://arxiv.org/abs/2309.15337", "parent": "swipe", "is_left_child": 1, "indirect_connections": ["summedits"], "coauthors": ["Jesse Vig", "Marti A. Hearst", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Beyond the Chat: Executable and Verifiable Text-Editing with LLMs", "summary": "How do we imagine writing with an LLM should look like. We design the concept of 'executable edits' that an LLM-based system can propose, and design a framework to verify factual accuracy of these edits (Warn-Verify-Audit).", "additional_links": {"demo video": "https://www.youtube.com/watch?v=q7lf5CIMyvE", "live demo": "https://inksync.salesforceresearch.ai/", "code": "https://github.com/SalesforceAIResearch/inksync", "recorded presentation": "https://www.youtube.com/watch?v=3RMo1nWIqCY"}},
        {"id": "art_or_artifice", "title": "Art or Artifice", "venue": "CHI2024", "url": "https://arxiv.org/abs/2309.14556", "parent": "swipe", "coauthors": ["Tuhin Chakrabarty", "Chien-Sheng Wu"], "full_title": "Art or Artifice? Large Language Models and the False Promise of Creativity", "summary": "Work led by Tuhin Chakrabarty as an intern at Salesforce Research. Are LLMs capable of high-quality creative fictional writing, to the level of short-stories published in the New Yorker. We designed a methodology to evaluate story quality (through rigorous manual evaluation by expert writers), and found a very large gap between professionally-written and AI-generated stories. Neat Finding: at the time, LLMs were not capable of even judging which stories were better than others, and tended to favor more bland AI-like writing.", "additional_links": {"code": "https://github.com/salesforce/creativity_eval", "data (hf)": "https://huggingface.co/datasets/Salesforce/ttcw_creativity_eval", "video": "https://dl.acm.org/doi/10.1145/3613904.3642731"}},
        {"id": "ai_writing_idiosyncracies", "title": "AI Writing Idiosyncracies", "venue": "arXiv", "url": "https://arxiv.org/abs/2409.14509", "parent": "art_or_artifice", "indirect_connections": ["inksync"], "coauthors": ["Tuhin Chakrabarty", "Chien-Sheng Wu"], "full_title": "Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits", "summary": "Work led by Tuhin at Salesforce Research. Following up on Art or Artifice. Lowering our expectation from a story (1000+ words) to a single paragraph (100-200 words). We find in a controlled experiment that LLMs still struggle to generate high-quality creative writing even in shorter form. Neat finding: when allowing an LLM to: (1) draft, (2) detect issues, (3) edit them through executable edits, then LLMs are capable of <b>improving</b> their writing!", "additional_links": {"code": "https://github.com/salesforce/creativity_eval/"}},
        {"id": "shuffle_test", "title": "Coherence: Shuffle Test", "venue": "ACL2021", "url": "https://arxiv.org/abs/2107.03448", "root_node": 1, "root_name": "LM Evaluation\n2020-now", "root_color": "#D1BDFF", "coauthors": ["Luke Dai", "Lucas Bandarkar", "Marti A. Hearst"], "full_title": "Can Transformer Models Measure Coherence In Text? Re-Thinking the Shuffle Test", "summary": "Basic experiment that shows that a commonly used test to measure coherence in text (the Shuffle test) is saturated and ineffective, and encouraging the community to use more complex forms of the test (k-block Shuffle test).", "additional_links": {"code": "https://github.com/tingofurro/shuffle_test", "video": "https://aclanthology.org/2021.acl-short.134.mp4"}},
        {"id": "quiz_design", "title": "QG: Quiz Design", "venue": "NAACL2022", "url": "https://arxiv.org/abs/2205.01730", "parent": "shuffle_test", "coauthors": ["Chien-Sheng Wu", "Lidiya Murakhovs'ka", "Wenhao Liu", "Caiming Xiong"], "full_title": "Quiz Design Task: Helping Teachers Create Quizzes with Automated Question Generation", "summary": "How do we evaluate question generation models (LLMs that generate questions). We recruited teachers/educators with experience designing exams, and asked them to use the QG models, finding that they tend to have strong agreement on questions they would select for an exam.", "additional_links": {"code": "https://github.com/salesforce/QGen"}},
        {"id": "nnd", "title": "Near-Negative Distinction", "venue": "EMNLP2022", "url": "https://arxiv.org/abs/2205.06871", "parent": "quiz_design", "coauthors": ["Chien-Sheng Wu", "Caiming Xiong"], "full_title": "Near-Negative Distinction: Giving a Second Life to Human Evaluation Datasets", "summary": "A proposed method to improve evaluation methodology of generative models in cases where multiple references/candidates have been annotated.", "additional_links": {"code": "https://github.com/salesforce/nnd_evaluation"}},
        {"id": "flipflop", "title": "FlipFlop Experiment", "venue": "arXiv", "url": "https://arxiv.org/abs/2311.08596", "parent": "nnd", "coauthors": ["Lidiya Murakhovs'ka", "Caiming Xiong", "Chien-Sheng Wu"], "full_title": "Are You Sure? Challenging LLMs Leads to Performance Drops in The FlipFlop Experiment", "summary": "What happens when you give an LLM a classification task, it gets it right, and you ask it `Are you sure?`. Universally, LLMs tend to flip their answer: favoring to a superficial agreement with the user over being accurate. We connect the FlipFlop effect with the connect of sycophancy in LLMs, and show that finetuning is not a panacea to cure the issue, although it helps a bit."},
        ]

        build_garden(papers);
    </script>

</body>
</html>

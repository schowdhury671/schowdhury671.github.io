<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>{{ sanjoy webpage }}</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="sanjoy" content="{{ sanjoy webpage }}" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="{{ site.baseurl }}/style.css" />
  <link rel="canonical" href="{{ page.url | replace:'index.html','' | prepend: site.baseurl | prepend: site.url }}">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Sanjoy Chowdhury
              </h1>
              <p>I am working as a Machine Learning Scientist with the Camera and Video AI team at <a href="https://sharechat.com/about">ShareChat</a>, India. I am also a visiting researcher at the Computer Vision and Pattern Recognition Unit at Indian Statistical Institute Kolkata under <a href="https://www.isical.ac.in/~ujjwal/"> Prof. Ujjwal Bhattacharya</a>.  
              </p>
              <p>
                From June 2019 to June 2021, I had worked as a Senior Research Engineer with the Vision Intelligence Group at <a href="https://research.samsung.com/sri-b">Samsung R&D Institute Bangalore</a>.  I primarily worked on developing novel AI powered solutions for different smart devices of Samsung. 
              </p>
              <p>
                I received my MTech in Computer Science & Engineering from <a href="https://www.iiit.ac.in/">IIIT Hyderabad</a>, where I was <b>Teaching Assistant (TA)</b> for <a href="https://ravika.github.io/">Prof. Ravi Kiran Sarvadevabhatla</a> and <a href="https://sites.google.com/view/iitkgpakdas/">Prof. Ashok Kumar Das</a> for the courses <b>Statistical Methods in AI</b> and <b>Discrete Mathematics and Algorithms</b> respectively. During my days at IIIT-H, I was fortunate to be advised by <a href="https://faculty.iiit.ac.in/~jawahar/">Prof. C V Jawahar</a>.
              </p>
	      <p>
		During my undergrad days, I had worked as research interns under <a href="http://cse.iitkgp.ac.in/~pabitra/">Prof. Pabitra Mitra </a> at IIT Kharagpur and at the CVPR Unit at ISI Kolkata under Prof. Ujjwal Bhattacharya. 
	      </p>
              <p style="text-align:center">
                <a target="_blank" href="https://mailhide.io/e/miMX3ZfK">Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/schowdhury671">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=CEdJKCIAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/sanjoy2528/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%;border-radius: 50%" alt="profile photo" src="../images/IMG-20200202-WA0044_2.jpg">
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Publications</h2>
              <p>
                I'm broadly interested in Computer vision, Deep learning, Multi-modal learning, Reinforcement learning areas and their various applications to solve real world problems involving but not limited to holistic scene understanding, domain adaptation etc. 
              </p>
            </td>
          </tr>
        </table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/audViSum_bmvc.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>AudViSum: Self-Supervised Deep Reinforcement Learning for Diverse Audio-Visual Summary Generation</h3>
              <br>
              <strong>Sanjoy Chowdhury*</strong>, Aditya P. Patra*, Subhrajyoti Dasgupta, Ujjwal Bhattacharya

              <br>
              <em>British Machine Vision Conference (<font color="#ff0000">BMVC</font>)</em>, 2021
              <br>
              
              <a href="https://www.bmvc2021-virtualconference.com/assets/papers/1430.pdf">Paper</a> / 
              
              <a href="https://github.com/schowdhury671/AudViSum">Code</a> / 
		    
              <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_1430.html">Slides</a> 
              
              <p></p>
              <p>Introduced a novel deep reinforcement learning based self-supervised audio-visual summarization model that leverages both audio and visual information to generate diverse yet semantically meaningful summaries.</p>

            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/rr_iccv.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>V-DESIRR: Very Fast Deep Embedded Single Image Reflection Removal</h3>
              <br>
              B H Pawan Prasad, Green Rosh K S, Lokesh R B, Kaushik Mitra, <strong>Sanjoy Chowdhury</strong>

              <br>
              <em>International Conference on Computer Vision (<font color="#ff0000">ICCV</font>)</em>, 2021
              <br>
              
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Prasad_V-DESIRR_Very_Fast_Deep_Embedded_Single_Image_Reflection_Removal_ICCV_2021_paper.pdf">Paper</a> /
              
              
              
              <a href="https://github.com/ee19d005/vdesirr">Code</a> 
              
              
              
<!--               <a href="https://github.com/ee19d005/vdesirr">slides</a>  -->
              
              <p></p>
              <p>We have proposed a multi-scale end to end architecture for detecting and removing weak, medium and strong reflections from naturally occurring images.</p>

            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/audVi_coseg_icip.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Listen to the Pixels</h3>
              <br>
              <strong>Sanjoy Chowdhury</strong>, Subhrajyoti Dasgupta, Sudip Das, Ujjwal Bhattacharya

              <br>
              <em>International Conference on Image Processing (<font color="#ff0000">ICIP</font>)</em>, 2021
              <br>
              
              <a href="https://ieeexplore.ieee.org/document/9506019">Paper</a> /
              
              
              
              <a href="https://github.com/schowdhury671/Audio-visual-joint-segmentation">Code</a> /
              
              
              
              <a href="https://sigport.org/documents/listen-pixels">Slides</a> 
              
              <p></p>
              <p>In this study, we exploited the concurrency between audio and visual modalities in an attempt to solve the joint audio-visual segmentation problem in a self-supervised manner.</p>

            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/fuzzy.jpeg" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>A Survey on Fuzzy Set Theoretic Approaches for Image Segmentation</h3>
              <br>
              Ajoy Mondal*, <strong>Sanjoy Chowdhury*</strong>

              <br>
              <em>ACM Computing Surveys</em>, 2021 (Under review)
              <br>
              
<!--               <a href="https://ieeexplore.ieee.org/document/9506019">Paper</a> / -->
              
              
              
<!--               <a href="https://github.com/schowdhury671/Audio-visual-joint-segmentation">code</a> / -->
              
              
              
<!--               <a href="https://sigport.org/documents/listen-pixels">slides</a> / -->
              
              <p></p>
              <p>The survey paper performs an in depth comparison and analysis on fuzzy set theory based image segmentation techniques.</p>

            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/not_too_deep_cnn.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Not Too Deep CNN for Face Detection in Real Life Scenario</h3>
              <br>
              <strong>Sanjoy Chowdhury</strong>, Parthasarathi Mukherjee, Ujjwal Bhattacharya

              <br>
              <em>International Conference on Next Generation Computing Technologies, Springer</em>, 2017 (<font color="#ff0000">Best paper award, Oral</font>)
              <br>
              
              <a href="https://link.springer.com/chapter/10.1007/978-981-10-8660-1_66">Paper</a> /
              
              
              
              <a href="https://github.com/schowdhury671/Not-too-deep-CNN">Code</a> 
              
              
              
<!--               <a href="https://github.com/schowdhury671/Not-too-deep-CNN">Slides</a>  -->
              
              <p></p>
              <p>Proposed a multi-scale face detection framework that is capable of detecting faces of multiple size and different orientations in low resolution images while achieving sufficiently low latency and modest detection rates in the wild.</p>

            </td>
          </tr>
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/citation.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Classification of Citation in Scientific Articles</h3>
              <br>
              <strong>Sanjoy Chowdhury</strong>, Harsh Vardhan, Pabitra Mitra, Dinabandhu Bhandari

              <br>
              <em>National Conference on Recent Advances in Science and Technology</em>, 2016 (<font color="#ff0000">Oral</font>)
              <br>
              
              <a href="https://github.com/schowdhury671/Citation-classification/blob/main/Citation_Classification_Abstract.docx">Abstract</a> /
              
              
              
              <a href="https://github.com/schowdhury671/Citation-classification">Code</a> 
              
              
              
              <p></p>
              <p>Designed a multi-class classification system to find out the type of citation i.e. a citation belongs to which facet. We aimed to
achieve this by extracting and analysing citation information from the text.</p>

            </td>
          </tr>
          
          </table>
          
        <br><br><br><br><br><br>
	      
	      
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Blog(s)</h2>
              <p>
                Have tried my hand at writing technical blogs.
              </p>
            </td>
          </tr>
        </table>
	            
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/Screenshot 2021-12-01 at 1.12.53 PM.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>The devil is in the details: Video Quality Enhancement Approaches</h3>
              <br>
              
              
              <a href="https://medium.com/sharechat-techbyte/the-devil-is-in-the-details-video-quality-enhancement-approaches-c382e42bf7ed">Link</a> 
              <p></p>
              <p>The blog contextualizes the problem of video enhancement in present day scenario and talks about a couple of interesting approaches to handle this challenging task.</p>
              
              <p></p>
              <p></p>

            </td>
          </tr>
          </table>
	      
	  <br><br><br><br><br><br> 
	      
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Selected projects</h2>
              <p>
                These include coursework, side projects and unpublished research work.
              </p>
            </td>
          </tr>
        </table>
	            
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/doc_unwarping.jpeg" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Document Image Unwarping</h3>
              <br>
              
              
              <a href="https://github.com/schowdhury671/Document-unwarping-">Code</a> 
              <p></p>
              <p>Worked towards proposing a novel end-to-end Deep Learning based method to unwarp arbitrarily curved and folded paper documents captured in the wild and extract text from it.</p>
              
              <p></p>
              <p></p>

            </td>
          </tr>
          </table>
	      
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/Screenshot 2021-11-09 at 12.38.43 AM.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Semi-Supervised Multi-View Correlation Feature Learning with Application to Webpage Classification</h3>
              <br>
              
              
              <a href="https://github.com/schowdhury671/Semi-Supervised-MultiView-Feature-Learning">Code</a> 
              
              <p>Implemented a semi-supervised multi-view correlation feature learning (SMCFL) approach, for webpage classification. SMCFL seeks for a discriminant common space by learning a multi-view shared transformation in a semi-supervised manner. This was done as a part of course project and contains implementation of <a href="https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14582/13925">paper</a> </p>
              

            </td>
          </tr>
          </table>  
	      
	      
	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="../images/Screenshot 2021-11-30 at 2.29.57 PM.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Bias-Free-Hatespeech-Detection</h3>
              <br>
              
              
              <a href="https://github.com/schowdhury671/Bias-Free-Hatespeech-Detection">Code</a> / 
	      <a href="https://arxiv.org/pdf/1707.00075.pdf"> Original paper </a>	    
              
              <p> Implemented a bias free hatespeech detection system leveraging adversarial learning. </p>
              

            </td>
          </tr>
          </table>    
        
	      <br><br><br><br><br><br>
        
      <div class="affiliations-outer-container">
				<h2 class="section-heading">Affiliations</h2>
	      <br><br>
	      			<table>
					<tr>
						<td style="padding-right: 3.4em;">
							<a href="http://www.iitkgp.ac.in/" target="_blank"><img style="width:80px"  src="../images/iit-kgp.jpeg"></a>
							<br>
							IIT Kharagpur<br>Apr-Sep 2016
						</td>
							
						<td style="padding-right: 3.4em;">
							<a href="https://www.isical.ac.in/" target="_blank"><img style="width:80px"  src="../images/isi.jpeg"></a>
							<br>
							ISI Kolkata<br>Feb-July 2017
						</td>
						
						<td style="padding-right: 3.4em;">
							<a href="https://www.iiit.ac.in/" target="_blank"><img style="width:80px", "height:140px"  src="../images/iiith.jpeg"></a>
							<br>
							IIIT Hyderabad<br>Aug 2017 - May 2019
						</td>
						
						<td style="padding-right: 3.4em;">
							<a href="https://www.iiit.ac.in/" target="_blank"><img style="width:80px", "height:120px"  src="../images/mentorgraphics.jpeg"></a>
							<br>
							Mentor Graphics Hyderabad<br>May - July 2018
						</td>
						
						<td style="padding-right: 3.4em;">
							<a href="https://research.samsung.com/sri-b" target="_blank"><img style="width:80px"  src="../images/SamsungResearch Logo.jpeg"></a>
							<br>
							Samsung Research Bangalore<br>June 2019 - June 2021
						</td>
						
						<td style="padding-right: 2.4em;">
							<a href="https://sharechat.com/about" target="_blank"><img style="width:80px"  src="../images/ShareChat_logo.png"></a>
							<br>
							ShareChat Bangalore<br>June 2021 - Present
						</td>
					</tr>
	      			</table>
       <br><br><br><br><br><br>
      <div class="news-container">
				<h2>News</h2>
				<table>
					<tr>
						<td style="padding-right: 0.7em;">
							Oct 2021
						</td>
							
						<td style="padding-right: 0.7em;">
							Paper on audio-visual summarization accepted in <font color="#ff0000">BMVC 2021</font>.
						</td>
					</tr>
					
					<tr>
						<td style="padding-right: 0.7em;">
							Sep 2021
						</td>
							
						<td style="padding-right: 0.7em;">
							My <font color="#ff0000">first blog</font> on Video Quality Enhancement released at Tech @ ShareChat.
						</td>
					</tr>
					
					<tr>
						<td style="padding-right: 0.7em;">
							July 2021
						</td>
							
						<td style="padding-right: 0.7em;">
							Paper on reflection removal got accepted in <font color="#ff0000">ICCV 2021</font>.
						</td>
					</tr>
					
					<tr>
						<td style="padding-right: 0.7em;">
							June 2021 
						</td>
							
						<td style="padding-right: 0.7em;">
							Joined <font color="#ff0000">ShareChat</font> Data Science team.

						</td>
					</tr>
					
					<tr>
						<td style="padding-right: 0.7em;">
							May 2021 
						</td>
							
						<td style="padding-right: 0.7em;">
							Paper on audio-visual joint segmentation accepted in <font color="#ff0000">ICIP 2021</font>.

						</td>
					</tr>
					
					<tr>
						<td style="padding-right: 0.7em;">
							Dec 2018 
						</td>
							
						<td style="padding-right: 0.7em;">
							Accepted <font color="#ff0000">Samsung Research</font> offer. Joined in June 2019.
 
						</td>
					</tr>
					
					<tr>
						<td style="padding-right: 0.7em;">
							Sep 2018
						</td>
							
						<td style="padding-right: 0.7em;">
							Received <font color="#ff0000">Dean's merit list award</font> for academic excellence at IIIT Hyderabad.
						</td>
					</tr>
					
					<tr>
						<td style="padding-right: 0.7em;">
							Oct 2017
						</td>
							
						<td style="padding-right: 0.7em;">
							Our work on multi-scale, low-latency face detection framework received <font color="#ff0000">Best Paper Award</font> at NGCT-2017.
						</td>
					</tr>
	      			</table>
			</div>
        
       
        
        
        
        <!-- credits -->
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Design and source code from <a style="font-size:small;margin-right" href="https://github.com/leonidk/new_website">Leonid Keselman</a>
              </p>
            </td>
          </tr>
        </table>


        
  </table>
</body>

</html>

